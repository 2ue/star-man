# ============================================
# 必需配置（必须设置的项目）
# ============================================

# GitHub Personal Access Token
# 需要至少 public_repo 权限
GITHUB_TOKEN=your_github_personal_access_token_here

# 数据库连接路径
# 相对路径基于项目根目录（包含 pnpm-workspace.yaml 的目录）
# SQLite 示例（相对路径，推荐）：./data/star-man.db
# SQLite 示例（绝对路径）：/absolute/path/to/database.db
# MySQL 示例：mysql://user:password@localhost:3306/star_man
# PostgreSQL 示例：postgresql://user:password@localhost:5432/star_man
DATABASE_URL=./data/star-man.db

# ============================================
# 可选配置（只有在需要时才设置）
# ============================================

# API 服务端口（只有启动 API 服务时才需要）
API_PORT=3801

# API 服务主机地址（仅在生产环境需要配置）
# 开发环境自动使用 0.0.0.0 避免 IPv4/IPv6 冲突
# 生产环境示例：
# API_HOST=localhost
# API_HOST=0.0.0.0

# ============================================
# 自动同步配置（仅用于首次初始化）
# 数据库中不存在配置时，才从这里读取
# 后续通过 Web UI、API 或 CLI 修改配置
#
# 注意：
# - AUTO_SYNC_ENABLED 如果不设置，默认视为 true（自动同步开启）
# - 只在首次初始化时读取，之后以数据库配置为准
# ============================================
AUTO_SYNC_ENABLED=true

# Cron 表达式配置
# 支持单个定时任务：
AUTO_SYNC_CRON=0 2 * * *
# 支持多个定时任务（使用逗号分隔）：
# AUTO_SYNC_CRON=0 2 * * *,0 14 * * *,0 22 * * *
# 说明：
#   0 2 * * *   - 每天凌晨 2:00
#   0 14 * * *  - 每天下午 14:00
#   0 22 * * *  - 每天晚上 22:00

AUTO_SYNC_TIMEZONE=Asia/Shanghai

# 启动时自动同步（仅影响 API 启动时是否立刻进行一次增量同步）
# 不设置时默认 true
AUTO_SYNC_ON_START=true

# ============================================
# AI 模型配置（可选）
# 不配置则不启用 AI 语义搜索 / 总结能力，
# 系统自动退回到普通排序与已有标签逻辑
# ============================================

# 可选值：
#   openai            - 使用 OpenAI 官方 API
#   openai-compatible - 使用兼容 OpenAI 协议的第三方服务 / 自建网关
#   ollama            - 使用本地 Ollama 模型
# 这里默认通过 OpenAI 兼容代理使用 Gemini 大模型
AI_PROVIDER=openai-compatible

# 模型名称：
# - OpenAI 示例：gpt-4o-mini, gpt-4.1-mini 等
# - Ollama 示例：llama3.1:8b, qwen2.5:7b 等
# - Gemini 示例（通过代理）：gemini-2.5-flash 等
AI_MODEL=gemini-2.5-flash

# 当 AI_PROVIDER 为 openai / openai-compatible 时必填
# 如果你的代理服务不校验 key，可以填任意非空字符串
OPENAI_API_KEY=your_gemini_proxy_api_key_here

# OpenAI 兼容服务地址（此处默认使用 Gemini 代理）
OPENAI_BASE_URL=http://43.156.131.208:8071/proxy/gemini-fufei

# 当 AI_PROVIDER=ollama 时可选，默认 http://localhost:11434
# OLLAMA_BASE_URL=http://localhost:11434
